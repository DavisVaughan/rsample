---
title: "Recipes with rsample"
vignette: >
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteIndexEntry{Recipes with rsample}
output:
  knitr:::html_vignette:
    toc: yes
---

The [`recipes`](https://topepo.github.io/recipes/) package contains a data preprocessor that can be used to avoid the potentially expensive formula methods as well as providing a richer set of data manipulation tools than base R can provide. 

In many cases, the preprocessing steps might contain quantities that require statistical estimation of parameters, such as

* signal extraction using principal component analysis

* imputation of missing values

* transformations of individual variables (e.g. Box-Cox transformations)

It is critical that any complex preprocessing steps be contained _inside_ of resampling so that the model performance estimates take into account the variability of these steps. 

Before discussing how `rsample` can use recipes, let's look at an example recipe for the job attrition data. 

## An Example Recipe

For illustration, the Ames housing data will be used. There are sale prices of homes along with various other descriptors for the property:

```{r ames-data, message=FALSE}
library(AmesHousing)
ames <- make_ames()
names(ames)
```

Suppose that we will again fit a simple regression regression model with the formula:

```{r form, eval = FALSE}
log10(Sale_Price) ~ Neighborhood + House_Style + Year_Sold + Lot_Area
```

The distribution of the lot size is right-skewed:

```{r build}
library(ggplot2)
theme_set(theme_bw())
ggplot(ames, aes(x = Lot_Area)) + 
  geom_histogram(binwidth = 5000, col = "red", fill ="red", alpha = .5)
```

It might benefit the model if we estimate a transformation of the data using the Box-Cox procedure. 

Also, note that the frequencies of the neighborhoods can vary:

```{r hood}
ggplot(ames, aes(x = Neighborhood)) + geom_bar() + coord_flip() + xlab("")
```

When these are resampled, some neighborhoods will not be included in the test set and this will result in a column of dummy variables with zero entires. The same is true for the `House_Style` variable. We might want to collapse rarely occurring values into "other" categories. 

To define the design matrix, an initial recipe is created: 

```{r rec_setup, message=FALSE, warning=FALSE}
library(recipes)

rec <- recipe(Sale_Price ~ Neighborhood + House_Style + Year_Sold + Lot_Area, 
              data = ames) %>%
  # Log the outcome
  step_log(Sale_Price, base = 10) %>%
  # Collapse rarely occurring jobs into "other"
  step_other(Neighborhood, House_Style, threshold = 0.05) %>%
  # Dummy variables on the qualitative predictors
  step_dummy(all_nominal()) %>%
  # Unskew a predictor
  step_BoxCox(Lot_Area) %>%
  # Normalize
  step_center(all_predictors()) %>%
  step_scale(all_predictors()) 
rec
```
This recreates the work that the formula method traditionally uses with the additional steps. 

While the original data object `ames` is used in the call, it is only used to define the variables and their characteristics so a single recipe is valid across all resampled versions of the data. The recipe can be estimated on the analysis component of the resample. 

If we execute the recipe on the entire data set:

```{r recipe-all}
rec_training_set <- prep(rec, training = ames, retain = TRUE, verbose = TRUE)
rec_training_set
```
To get the values of the data, the `bake` function can be used: 

```{r baked}
# used a selector, `everything()` to get all the variables back
bake(rec_training_set, newdata = head(ames), everything())
```
Note that there are fewer dummy variables for `Neighborhood` and `House_Style` than in the data. 

Also, `retain` keeps the processed version of the data set so that we don't have to reapply the steps to extract the processed values. For the data used to train the recipe, we would have used:

```{r juiced}
juice(rec_training_set, everything()) %>% head
```

There are two ways to use recipes with `rsample`. The first embeds the recipe in the split objects. The second approach is to keep the trained recipes in their own column of the data. 

The next two sections will explore each method using bootstrap resampling:

```{r boot}
library(rsample)
set.seed(7712)
bt_samples <- bootstraps(ames)
bt_samples
bt_samples$splits[[1]]
```

## Approach #1: Embedding the Recipe

In this case, an initial recipe is defined and formally added to the resampling object:

```{r embed}
# Let's make a copy of the splits
bt_embed <- bt_samples
# Add the recipe 
bt_embed <- bt_embed %>% add_recipe(rec, prep = TRUE)
# The "+" indicates that the split contains a recipe
bt_embed$splits[[1]]
```


The `prep` option estimates the recipe values on the individual analysis sets. 

The benefit of using this method is that the `analysis` and `assessment` functions can returned the processed values instead of the raw data. For example, to get the house style values back on the holdout set:

```{r analysis}
assessment(bt_embed$splits[[1]], starts_with("House_Style")) %>%
  head
```
This allows for a more compact syntax that avoids having to explicitly `prep`, `bake`, or `juice` the recipe.

If you still want the unprocessed data, the `recipe` option can be used:

```{r original}
assessment(bt_embed$splits[[1]], recipe = FALSE) %>%
  select(starts_with("House_Style")) %>%
  head
```
Note that the selectors are not used inside of `assessment` when `recipe = FALSE`. 

To create the models, a fit function might be:

```{r embed-fit}
fit_lm_embed <- function(split_obj, ...) 
  lm(..., data = analysis(split_obj, all_predictors(), all_outcomes()))

library(purrr)
# Note that `Sale_Price` is on the log scale when processed by the recipe.
bt_embed$lm_mod <- map(bt_embed$splits, fit_lm_embed, Sale_Price ~ .)
bt_embed
```

To get the predictions:

```{r embed-pred}
pred_lm_embed <- function(split_obj, model_obj, ...) {
  out <- assessment(split_obj, all_outcomes())
  out$predicted <- predict(model_obj, newdata = assessment(split_obj, all_predictors()))
  out
}
bt_embed$pred <- map2(bt_embed$splits, bt_embed$lm_mod, pred_lm_embed)
bt_embed
```
Now to get the root-mean-squared error (RMSE):

```{r embed-rmse}
rmse <- function(dat) 
  sqrt(mean((dat$Sale_Price - dat$predicted)^2))
bt_embed$RMSE <- map_dbl(bt_embed$pred, rmse)
summary(bt_embed$RMSE)
```


## Approach #2: Separate Column(s)

In this case, we add a recipe column to the tibble. `rsample` has a connivence function called `prepper` that can be used to call `prep` but has the split object as the first argument (for easier purrring):

```{r col-pred}
bt_samples$recipes <- map(bt_samples$splits, prepper, recipe = rec, retain = TRUE)
bt_samples
bt_samples$recipes[[1]]
```

Now, to fit the model, the fit function only needs the recipe as input. This is because the above code used `retain = TRUE`. Otherwise, the split objects would also be needed to `bake` the recipe (as it will in the prediction function below). 

```{r cols-fit}
fit_lm <- function(rec_obj, ...) {
  mod_data <- juice(rec_obj, all_predictors(), all_outcomes()) 
  lm(..., data = mod_data)
}

bt_samples$lm_mod <- 
  map(
    bt_samples$recipes, 
    fit_lm, 
    Sale_Price ~ .
  )
bt_samples
```

To get predictions, the function needs three arguments: the splits (to get the assessment data), the recipe (to process them), and the model. To iterate over these, the function `purrr:pmap` is used: 

```{r cols-pred}
pred_lm <- function(split_obj, rec_obj, model_obj, ...) {
  mod_data <- bake(
    rec_obj, 
    newdata = assessment(split_obj),
    all_predictors(),
    all_outcomes()
  ) 
  
  out <- mod_data %>% select(Sale_Price)
  out$predicted <- predict(model_obj, newdata = mod_data %>% select(-Sale_Price))
  out
}

bt_samples$pred <- 
  pmap(
    lst(
      split_obj = bt_samples$splits, 
      rec_obj = bt_samples$recipes, 
      model_obj = bt_samples$lm_mod
    ),
    pred_lm 
  )
bt_samples
```

Calculating the RMSE is the same:

```{r cols-rmse}
bt_samples$RMSE <- map_dbl(bt_samples$pred, rmse)
summary(bt_samples$RMSE)
# and previously:
summary(bt_embed$RMSE)
```

## Summary

Either of these approaches should work. For embedding, there is the benefit of simpler code being required. The downsides are that there can only be one "active" recipe at a time and that the recipe objects are somewhat obfuscated. As an example of the latter point, it is slightly easier to get the values of the Box-Cox parameters when the recipe is in the tibble:

```{r bc}
map_df(bt_samples$recipes, tidy, number = 4)

# or 
foo <- function(x, ...) 
  tidy(x$recipe, ...)
map_df(bt_embed$splits, foo, number = 4)
```